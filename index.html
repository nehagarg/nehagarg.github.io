<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Neha Garg</title>

    <meta name="author" content="Neha Garg">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Neha Garg
                </p>
                <p>I'm a research fellow at <a href="https://www.ntu.edu.sg/rris"> Rehabilitation Research Institute of Singapore (RRIS)</a> at <a href="https://www.ntu.edu.sg">NTU</a>, Singapore
                  , where I am working on human robot interaction algorithms for assitive robotic wheelchair and robotic arm. 
                 </p> <p> I received my PhD degree from (<a href="https://www.nus.edu.sg">NUS</a>)
                  <!-- , School of Computing under NUS Graduate Schoolâ€™s Integrative Sciences and Engineering Programme (ISEP) --> in 2020 
                  during which I worked on autonomous grasping under uncertainty using POMDPs.
                  Prior to that, I worked as a Software Engineer at a computer vision startup Kooaba in Zurich, and a mobile software development company Affle in Singapore.
                  I received my B.Tech in Computer Science from <a href="https://www.iitd.ac.in/">IIT Delhi</a>, India and Masters in Computer Science from <a href="https://www.epfl.ch/en/">EPFL</a>, Switzerland.  

                  </p>
                  <p>
                  My area of research lies at the intersection of planning under uncertainty, machine learning and human robot interaction. 
                  I am interested in exploring how planning approaches can be combined with large vision language models to develop AI systems capable of reasoning in complex and dynamic environments.
                    
                </p>
                <p>
                  .
                </p>
                <p style="text-align:center">
                  <a href="mailto:priyadarshini.neha@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV_Neha_P_Garg.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/Neha_Garg_bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=WJWPtgcAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> &nbsp;/&nbsp;
				  <!-- <a href="https://www.threads.net/@jonbarron">Threads</a> &nbsp;/&nbsp; -->
				  <!-- <a href="https://bsky.app/profile/jonbarron.bsky.social">Bluesky</a> &nbsp;/&nbsp; -->
                  <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/nehagarg/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/NehaGarg_pic.png"><img style="width:70%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/NehaGarg_pic.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <!--<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Representative papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table> -->

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Selected Publications </h2>
            </td>
          </tr>
        </tbody></table>
          
        
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


      <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/Manipulation_shared_autonomy_overview.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <!--<a href="https://smerf-3d.github.io/">
          <span class="papertitle">SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration</span>
        </a>-->
        <span class="papertitle">Shared Autonomy of a Robotic Manipulator for Grasping under Human Intent Uncertainty using POMDPs</span>
        <br>
		<a href="https://www.ntu.edu.sg/rris/about-us/our-people/researcher-staff/j-anne-yow">J-Anne Yow</a>,
		<strong>Neha P Garg</strong>,
		<a href="https://dr.ntu.edu.sg/cris/rp/rp00218">Wei Tech Ang</a>
        <br>
        <em>IEEE Transanctions on robotics (T-RO) </em>, 2023
        <br>
        <a href="https://ieeexplore.ieee.org/document/10323205">paper link</a>
        /
        <a href="https://youtu.be/1K4aoJQg48c">video</a>
        <!--/
        <a href="https://arxiv.org/abs/2312.07541">arXiv</a>
        -->
        <p></p>
        <p>
          Introducing active information gathering in shared autonomy in a principled manner by modelling it as a discrete action partially observable Markov decision process (POMDP), reasoning over high-level actions.
        </p>
      </td>
    </tr>
	
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/dwa_vs_belief.png' width=100% >
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <!--<a href="https://smerf-3d.github.io/">
          <span class="papertitle">SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration</span>
        </a>-->
        <span class="papertitle">An intention prediction-based shared control system for point-to-point
          navigation of a robotic wheelchair</span>
        <br>
		<a href="https://www.ntu.edu.sg/rris/about-us/our-people/rris-students/lei-zhen">Zhen Lei</a>,
		<a href="">Bang Yi Tan</a>,
		<strong>Neha P Garg</strong>,
    <a href="https://www.ntu.edu.sg/rris/about-us/our-people/researcher-staff/dr-li-lei">Lei Li</a>,
		<a href="https://www.ntu.edu.sg/rris/about-us/our-people/researcher-staff/dr-ananda-sidarta">Ananda Sidarta</a>,
    <a href="https://dr.ntu.edu.sg/cris/rp/rp00218">Wei Tech Ang</a>
        <br>
        <em>IEEE Robotics and Automation Letters (RAL) </em>, 2022
        <br>
        <a href="https://ieeexplore.ieee.org/document/9817650">paper link</a>
        /
        <a href="https://youtu.be/uwXJHwz5_vg">video</a>
        <!--/
        <a href="https://arxiv.org/abs/2312.07541">arXiv</a>
        -->
        <p></p>
        <p>
          Assist in avoiding obstacles and moving in desired direction even with imprecise control input.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/Despot-alpha-tree-belief-action.png' width=100% >
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <!--<a href="https://smerf-3d.github.io/">
          <span class="papertitle">SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration</span>
        </a>-->
        <span class="papertitle">Despot-alpha: Online pomdp planning with large state and
          observation spaces</span>
        <br>
		<strong>Neha P Garg</strong>,
     <a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu</a>,
    <a href="https://www.comp.nus.edu.sg/~leews/">Wee Sun Lee</a>
        <br>
        <em>Robot Science and Systems (RSS) </em>, 2019
        <br>
        <a href="https://www.roboticsproceedings.org/rss15/p06.pdf">pdf</a>
        /
        <a href="https://github.com/nehagarg/hyp-despot-alpha-dev">code</a>
        <!--/
        <a href="https://arxiv.org/abs/2312.07541">arXiv</a>
        -->
        <p></p>
        <p>
          Online POMDP solver for large state and observation spaces by making use of weighted particles and alpha vectors inside a determinized forward search tree.

        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/HouseholdObjectsTestValidateWithObjectClasses.png' width=100% >
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <!--<a href="https://smerf-3d.github.io/">
          <span class="papertitle">SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration</span>
        </a>-->
        <span class="papertitle">Learning to grasp under uncertainty using pomdps</span>
        <br>
		<strong>Neha P Garg</strong>,
     <a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu</a>,
    <a href="https://www.comp.nus.edu.sg/~leews/">Wee Sun Lee</a>
        <br>
        <em>Internation Conference on Robotics and Automation (ICRA) </em>, 2019
        <br>
        <a href="https://ieeexplore.ieee.org/document/8793818">paper link</a>
        /
        <a href="https://github.com/nehagarg/autonomousGrasping">code</a>
        /
        <a href="https://youtu.be/X0l_XF_3nvM">video</a>
        <p></p>
        <p>
          Autonomous grasping under uncertainty using touch and vision feedback by learning from a POMDP policy.

        </p>
      </td>
    </tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Stolen from <a href="https://github.com/jonbarron/website">Jon Barron</a> 
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
